{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.986605,
     "end_time": "2020-05-23T00:16:33.493830",
     "exception": false,
     "start_time": "2020-05-23T00:16:32.507225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append(_dh[0].split(\"knowknow\")[0])\n",
    "from knowknow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Counting coocurrences\n",
       "\n",
       "Cultural phenomena are rich in meaning and context. Moreover, the meaning and context are what we care about, so stripping that would be a disservice. \"Consider Geertz:\"\n",
       "> Not only is the semantic structure of the figure a good deal more complex than it appears on the surface, but an analysis of that structure forces one into tracing a multiplicity of referential connections between it and social reality, so that the final picture is one of a configuration of dissimilar meanings out of whose interworking both the expressive power and the rhetorical force of the final symbol derive. (Geertz [1955] 1973, Chapter 8 Ideology as a Cultural System, p. 213)\n",
       "\n",
       "The way people understanding their world shape their action, and understandings are heterogeneous in any community, woven into a complex web of interacting pieces and parts. Understandings are constantly evolving, shifting with every conversation or Breaking News. Any quantitative technique for studying meaning must be able to capture the relational structure of cultural objects, their temporal dynamics, or it cannot be meaning.\n",
       "\n",
       "These considerations motivate how I have designed the data structure and code for this project. My attention to \"cooccurrences\" in what follows is an application of Levi Martin and Lee's (2018) formal approach to meaning. They develop the symbolic formalism I use below, as well as showing several general analytic strategies for inductive, ground-up meaning-making from count data. This approach is quite general, useful for many applications.\n",
       "\n",
       "The process is rather simple, I count cooccurrences between various attributes. For each document, for each citation in that document, I increment a dozen counters, depending on attributes of the citation, paper, journal, or author. This counting process is done once, and can be used as a compressed form of the dataset for all further analyses. In the terminology of Levi Martin and Lee, I am constructing \"hypergraphs\", and I will use their notation in what follows. For example $[c*fy]$ indicates the dataset which maps from $(c, fy) \\to count$.\n",
       "$c$ is the name of the cited work. $fy$ is the publication year of the article which made the citation. $count$ is the number of citations which are at the intersection of these properties.\n",
       "\n",
       "+ $[c]$ the number of citations each document receives\n",
       "+ $[c*fj]$ the number of citations each document receives from each journal's articles\n",
       "+ $[c*fy]$ the number of citations each document receives from each year's articles\n",
       "+ $[fj]$ the number of citations from each journal\n",
       "+ $[fj*fy]$ the number of citations in each journal in each year\n",
       "+ $[t]$ cited term total counts\n",
       "+ $[fy*t]$ cited term time series\n",
       "+ term cooccurrence with citation and journal ($[c*t]$ and [fj*t]$)\n",
       "+ \"author\" counts, the number of citations by each author ($[a]$ $[a*c]$ $[a*j*y]$)\n",
       "+ [c*c]$, the cooccurrence network between citations\n",
       "+ the death of citations can be studied using the $[c*fy]$ hypergraph\n",
       "+ $[c*fj*t]$ could be used for analyzing differential associations of $c$ to $t$ across publication venues\n",
       "+ $[ta*ta]$, $[fa*fa]$, $[t*t]$ and $[c*c]$ open the door to network-scientific methods\n",
       "\n",
       "\n",
       "\n",
       "# References\n",
       "\n",
       "\n",
       "\n",
       "+ Martin, John Levi, and Monica Lee. 2018. “A Formal Approach to Meaning.” Poetics 68(February):10–17.\n",
       "+ Geertz, Clifford. 1973. The Interpretation of Cultures. New York: Basic Books, Inc."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showdocs(\"counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017952,
     "end_time": "2020-05-23T00:16:33.530698",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.512746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# README\n",
    "\n",
    "First, you need to get some data. In accordance with JSTOR's usage policies, I **do not provide any full-text data**. And that's the data you need to use this notebook.\n",
    "You can obtain your own data by requesting full OCR data packages through JSTOR's [Data for Research](https://www.jstor.org/dfr/) initiative. \n",
    "\n",
    "Make sure to read carefully through \"User Settings.\" Set the appropriate settings, and run the entire notebook.\n",
    "\n",
    "This will create a new \"database\" of counts, which can be recalled by running `my_counts = get_cnt( '<DB_NAME_HERE>' )`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015957,
     "end_time": "2020-05-23T00:16:33.563610",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.547653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# User Settings\n",
    "\n",
    "`database_name` is the name you choose for the final dataset of counts\n",
    "\n",
    "`zipdir` is the directory which contains the `.zip` files JSTOR provides to you (not included)\n",
    "\n",
    "`mode` choose between \"basic\" and \"all\" mode\n",
    "\n",
    "1. \"basic\" mode\n",
    "    + this mode is not typically faster than `everything`, but it does reduce RAM overhead\n",
    "        + on ~200k articles the running counters take up more than 16GB RAM\n",
    "        + to counter this, I first run simple statistics, then rerun this notebook again, filtering based on the descriptive statistics\n",
    "    + includes `c` counts, the number of citations each document receives\n",
    "    + includes `c.fj` counts, the number of citations each document receives from each journal's articles\n",
    "    + includes `c.fy` counts, the number of citations each document receives from each year's articles\n",
    "    + includes `fj` counts, the number of citations from each journal\n",
    "    + includes `fj.fy` counts, the number of citations in each journal in each year\n",
    "    + includes `t` `fy.t` counts, for term time series and filtering\n",
    "\n",
    "2. \"all\" mode\n",
    "    + you must run this if you want to run all analyses included in this project\n",
    "    + includes all counts from `basic` mode\n",
    "    + includes term cooccurrence with citation and journal (`c.t` `fj.t`)\n",
    "    + includes \"author\" counts, the number of citations by each author (`a` `a.c` `a.j.y`)\n",
    "    + includes `c.c`, the cooccurrence network between citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2020-05-23T00:16:33.603504",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.581562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "database_name = 'sociology-jstor-basicall'\n",
    "zipdir = 'G:/My Drive/projects/qualitative analysis of literature/pre 5-12-2020/003 process JSTOR output/RaW dAtA/'\n",
    "mode = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016955,
     "end_time": "2020-05-23T00:16:33.638410",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.621455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I use citation and journal filters while counting. \n",
    "This filtering is important when working with large datasets. You can run the \"trend summaries/cysum\" on a `basic` database, and use the variable it automatically generates, `\"<DBNAME>.included_citations\"` to modify which citations to use when computing the `all` database.\n",
    "\n",
    "In most cases, it's best to set `use_included_citations_filter` and `use_included_journals_filter` both to `False` the first time you run this notebook on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.051889,
     "end_time": "2020-05-23T00:16:33.707253",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.655364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_included_citations_filter = True\n",
    "use_included_journals_filter = True\n",
    "\n",
    "# not necessary if you're not filtering based on citations and journals pre-count\n",
    "included_citations = load_variable(\"sociology-jstor.included_citations\")\n",
    "included_journals = ['Acta Sociologica', 'Administrative Science Quarterly', 'American Journal of Political Science', 'American Journal of Sociology', 'American Sociological Review', 'Annual Review of Sociology', 'BMS: Bulletin of Sociological Methodology / Bulletin de Méthodologie Sociologique', 'Berkeley Journal of Sociology', 'Contemporary Sociology', 'European Sociological Review', 'Hitotsubashi Journal of Social Studies', 'Humboldt Journal of Social Relations', 'International Journal of Sociology', 'International Journal of Sociology of the Family', 'International Review of Modern Sociology', 'Journal for the Scientific Study of Religion', 'Journal of Health and Social Behavior', 'Journal of Marriage and Family', 'Language in Society', 'Michigan Sociological Review', 'Polish Sociological Review', 'Review of Religious Research', 'Social Forces', 'Social Indicators Research', 'Social Problems', 'Social Psychology Quarterly', 'Sociological Bulletin', 'Sociological Focus', 'Sociological Forum', 'Sociological Methodology', 'Sociological Perspectives', 'Sociological Theory', 'Sociology', 'Sociology of Education', 'Sociology of Religion', 'Symbolic Interaction', 'The American Sociologist', 'The British Journal of Sociology', 'The Canadian Journal of Sociology', 'The Sociological Quarterly', 'Theory and Society']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043911,
     "end_time": "2020-05-23T00:16:33.768096",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.724185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Terms are iteratively pruned. After `CONSOLIDATE_EVERY_N_CITS` citations are counted, the algorithm will keep only the top `NUM_TERMS_TO_KEEP` terms, blacklisting the rest and not counting them anymore. This doesn't hurt the dataset, but dramatically reduces the RAM overhead and the size of the final dataset on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.019947,
     "end_time": "2020-05-23T00:16:33.804998",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.785051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONSOLIDATE_TERMS = True\n",
    "\n",
    "NUM_TERMS_TO_KEEP = 5000\n",
    "\n",
    "CONSOLIDATE_EVERY_N_CITS = NUM_TERMS_TO_KEEP*3\n",
    "#CONSOLIDATE_EVERY_N_CITS = 1000\n",
    "\n",
    "NPERYEAR = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022938,
     "end_time": "2020-05-23T00:16:33.844891",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.821953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's also convenient to be able to rename various entities. There were a few different names for the Canadian Journal of Sociology. If you want to filter on something other than journals, you'll have to modify the code and add this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2020-05-23T00:16:33.884785",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.862843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "journal_map = {} # default\n",
    "journal_map = {\n",
    "    \"Canadian Journal of Sociology / Cahiers canadiens de sociologie\": 'The Canadian Journal of Sociology',\n",
    "    \"The Canadian Journal of Sociology / Cahiers canadiens de\\n                sociologie\": 'The Canadian Journal of Sociology',\n",
    "    'The Canadian Journal of Sociology / Cahiers canadiens de sociologie': 'The Canadian Journal of Sociology'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017952,
     "end_time": "2020-05-23T00:16:33.918693",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.900741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.323136,
     "end_time": "2020-05-23T00:16:34.258784",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.935648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "from nltk import sent_tokenize\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./creating variables/'))\n",
    "\n",
    "# library functions for cleaning and extracting in-text citations from OCR\n",
    "from cnt_cooc_jstor_lib import (\n",
    "    citation_iterator, getOuterParens, \n",
    "    Document, ParseError, \n",
    "    clean_metadata\n",
    ")\n",
    "\n",
    "# XML parser\n",
    "from lxml.etree import _ElementTree as ElementTree\n",
    "from lxml import etree\n",
    "recovering_parser = etree.XMLParser(recover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.022939,
     "end_time": "2020-05-23T00:16:34.301669",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.278730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting ready for term counting\n",
    "from nltk.corpus import stopwords as sw\n",
    "stopwords = set(sw.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.022939,
     "end_time": "2020-05-23T00:16:34.361509",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.338570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zipfiles = list(Path(zipdir).glob(\"*.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018938,
     "end_time": "2020-05-23T00:16:34.398410",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.379472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01697,
     "end_time": "2020-05-23T00:16:34.433332",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.416362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following helper function `file_iterator` iterates through all documents inside a list of zipfiles\n",
    "\n",
    "Each iteration returns:\n",
    "1. the document DOI\n",
    "2. the metadata file contents\n",
    "3. the ocr file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.023937,
     "end_time": "2020-05-23T00:16:34.475220",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.451283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getname(x):\n",
    "    x = x.split(\"/\")[-1]\n",
    "    x = re.sub(r'(\\.xml|\\.txt)','',x)\n",
    "    return x\n",
    "\n",
    "def file_iterator(zipfiles):\n",
    "    from random import shuffle\n",
    "    \n",
    "    all_files = []\n",
    "    for zf in zipfiles:\n",
    "        archive = ZipFile(zf, 'r')\n",
    "        files = archive.namelist()\n",
    "        names = list(set(getname(x) for x in files))\n",
    "        \n",
    "        all_files += [(archive,name) for name in names]\n",
    "        \n",
    "    shuffle(all_files)\n",
    "        \n",
    "    for archive, name in all_files:\n",
    "        try:\n",
    "            yield(\n",
    "                name.split(\"-\")[-1].replace(\"_\", \"/\"),\n",
    "                archive.read(\"metadata/%s.xml\" % name),\n",
    "                archive.read(\"ocr/%s.txt\" % name).decode('utf8')\n",
    "            )\n",
    "        except KeyError: # some very few articles don't have both\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017951,
     "end_time": "2020-05-23T00:16:34.511128",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.493177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`get_page_strings` takes the string contents of an XML file produced by JSTOR. The XML file in question represents the text of a given article. This function cleans the text for OCR peculiarities, and splits the document into pages for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.024942,
     "end_time": "2020-05-23T00:16:34.553025",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.528083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basic_ocr_cleaning(x):\n",
    "    # remove multiple spaces in a row\n",
    "    x = re.sub(r\" +\", ' ', str(x))\n",
    "    # remove hyphenations [NOTE this should be updated, with respect to header and footer across pages...]\n",
    "    x = re.sub(r\"([A-Za-z]+)-\\s+([A-Za-z]+)\", \"\\g<1>\\g<2>\", x)\n",
    "    \n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "def get_content_string(ocr_string):\n",
    "    docXml = etree.fromstring(ocr_string, parser=recovering_parser)\n",
    "    pages = docXml.findall(\".//page\")\n",
    "\n",
    "    page_strings = []\n",
    "    for p in pages:\n",
    "        if p.text is None:\n",
    "            continue\n",
    "        page_strings.append(p.text)\n",
    "\n",
    "    secs = docXml.findall(\".//sec\")\n",
    "\n",
    "    for s in secs:\n",
    "        if s.text is None:\n",
    "            continue\n",
    "        if s.text.strip() == '':\n",
    "            try_another = etree.tostring(s, encoding='utf8', method='text').decode(\"utf8\").strip()\n",
    "            #print(try_another)\n",
    "            if try_another == '':\n",
    "                continue\n",
    "\n",
    "            page_strings.append(try_another)\n",
    "        else:\n",
    "            page_strings.append(s.text.strip())\n",
    "\n",
    "    return basic_ocr_cleaning( \"\\n\\n\".join(page_strings) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.240891,
     "end_time": "2020-05-23T00:16:34.810862",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.569971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`consolidate terms` was built to eliminate all terms which are not in the top `NUM_TERMS_TO_KEEP`.\n",
    "This is done by sorting `fromyear-term`, or `fy.t` counts in descending order. The top entry here is the term-year pair which accumulated the most appearances in citation contexts. I take the top 1000 `t`'s in this sorted list and preserve them, and blacklist the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.02992,
     "end_time": "2020-05-23T00:16:34.859731",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.829811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "term_whitelist = set()\n",
    "\n",
    "def consolidate_terms():\n",
    "    global term_whitelist, CONSOLIDATION_CUTOFF\n",
    "    \n",
    "\n",
    "    have_now = set(cnt_doc['t'])\n",
    "    # this is where the filtering occurs\n",
    "    \n",
    "    to_keep = set()\n",
    "    if True:\n",
    "        \n",
    "        # takes terms based on the maximum number I can take...\n",
    "        terms = list(cnt_doc['t'].keys())\n",
    "        counts = np.array([cnt_doc['t'][k] for k in terms])\n",
    "        argst = list(reversed(np.argsort(counts)))\n",
    "        \n",
    "        to_keep = [terms[i] for i in argst if '-' in terms[i][0]][:NUM_TERMS_TO_KEEP//2] # half should be 2-tuples\n",
    "        to_keep += [terms[i] for i in argst if not '-' in terms[i][0]][:NUM_TERMS_TO_KEEP//2] # half should be 1-tuples\n",
    "        \n",
    "        to_remove = have_now.difference(to_keep)\n",
    "        to_remove = set(\"-\".join(x) for x in to_remove)\n",
    "            \n",
    "    \n",
    "    if False:\n",
    "        # takes the top 5000 terms in terms of yearly count\n",
    "        sort_them = sorted(cnt_doc['fy.t'], key=lambda x: -cnt_doc['fy.t'][x])\n",
    "        to_keep = defaultdict(set)\n",
    "        \n",
    "        i = 0\n",
    "        while not len(to_keep) or (\n",
    "            min(len(x) for x in to_keep.values()) < NPERYEAR and \n",
    "            i < len(sort_them)\n",
    "        ):\n",
    "            # adds the term to the year set, if it's not already \"full\"\n",
    "            me = sort_them[i]\n",
    "            me_fy, me_t = me\n",
    "            \n",
    "            # eventually, we don't count it :P\n",
    "            if cnt_doc['t'][me_t] < CONSOLIDATION_CUTOFF:\n",
    "                break\n",
    "            \n",
    "            if len(to_keep[me_fy]) < NPERYEAR:\n",
    "                to_keep[me_fy].add(me_t) \n",
    "            i += 1\n",
    "            \n",
    "        if False: # useful for debugging\n",
    "            print({\n",
    "                k: len(v)\n",
    "                for k,v in to_keep.items()\n",
    "            })\n",
    "            \n",
    "        to_keep = set(chain.from_iterable(x for x in to_keep.values()))\n",
    "        to_remove = have_now.difference(to_keep)\n",
    "    \n",
    "    \n",
    "    # so that we never log counts for these again:\n",
    "    term_whitelist.update(to_keep)\n",
    "\n",
    "    # the rest of the code is pruning all other term counts for this term in memory\n",
    "    print(\"consolidating... removing\", len(to_remove), 'e.g.', sample(to_remove,5))\n",
    "    \n",
    "    to_prune = ['t','fy.t','fj.t','c.t']\n",
    "    for tp in to_prune:\n",
    "        \n",
    "        whichT = tp.split(\".\").index('t') # this checks where 't' is in the name of the variable (first or second?)\n",
    "\n",
    "        print(\"pruning '%s'...\" % tp)\n",
    "\n",
    "        tydels = [x for x in cnt_doc[tp] if x[ whichT ] in to_remove]\n",
    "            \n",
    "        print(\"old size:\", len(cnt_doc[tp]))\n",
    "        for tr in tydels:\n",
    "            del cnt_doc[tp][tr]\n",
    "            del cnt_ind[tp][tr]\n",
    "        print(\"new size:\", len(cnt_doc[tp]))\n",
    "        \n",
    "    \n",
    "    print(\"final terms: \", \", \".join( sample(list(\"-\".join(list(x)) for x in cnt_doc['t']), 200) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016954,
     "end_time": "2020-05-23T00:16:34.894637",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.877683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Counting algorithm\n",
    "\n",
    "The following cells contain the counting function, which accounts for a document in various ways.\n",
    "This function should be relatively simple to extend, if you want to count other combinations, or different attributes altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.021974,
     "end_time": "2020-05-23T00:16:34.933640",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.911666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt_ind = defaultdict(lambda:defaultdict(int))\n",
    "track_doc = defaultdict(lambda:defaultdict(set))\n",
    "cnt_doc = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "def cnt(term, space, doc):\n",
    "    # it's a set, yo\n",
    "    track_doc[space][term].add(doc)\n",
    "    # update cnt_doc\n",
    "    cnt_doc[space][term] = len(track_doc[space][term])\n",
    "    # update ind count\n",
    "    cnt_ind[space][term] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.032995,
     "end_time": "2020-05-23T00:16:34.984587",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.951592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cits = 0\n",
    "last_print = 0\n",
    "citations_skipped = 0\n",
    "\n",
    "def account_for(doc):\n",
    "    global cits, last_print, mode, citations_skipped\n",
    "    \n",
    "    # consolidating \"terms\" counter as I go, to limit RAM overhead\n",
    "    # I'm only interested in the most common 1000\n",
    "    if CONSOLIDATE_TERMS and \\\n",
    "            not len(term_whitelist) and \\\n",
    "            cits - last_print > CONSOLIDATE_EVERY_N_CITS:\n",
    "        print(\"Citation %s\" % cits)\n",
    "        print(\"Term %s\" % len(cnt_doc['t']))\n",
    "        #print(sample(list(cnt_doc['t']), 10))\n",
    "        last_print = cits\n",
    "        consolidate_terms()\n",
    "\n",
    "\n",
    "    if 'citations' not in doc or not len(doc['citations']):\n",
    "        #print(\"No citations\", doc['doi'])\n",
    "        return\n",
    "\n",
    "    for c in doc['citations']:\n",
    "        if 'contextPure' not in c:\n",
    "            raise Exception(\"no contextPure...\")\n",
    "\n",
    "\n",
    "\n",
    "        for cited in c['citations']:\n",
    "            \n",
    "            if use_included_citations_filter and (cited not in included_citations):\n",
    "                citations_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            cits += 1\n",
    "            cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "            # citation\n",
    "            cnt(cited, 'c', doc['doi'])\n",
    "\n",
    "            # journal\n",
    "            cnt(doc['journal'], 'fj', doc['doi'])\n",
    "\n",
    "            # journal year\n",
    "            cnt((doc['journal'], doc['year']), 'fj.fy', doc['doi'])\n",
    "\n",
    "            # citation journal\n",
    "            cnt((cited, doc['journal']), 'c.fj', doc['doi'])\n",
    "\n",
    "            # citation year\n",
    "            cnt((cited, doc['year']), 'c.fy', doc['doi'])\n",
    "\n",
    "            \n",
    "        # constructing the tuples set :)\n",
    "        sp = c['contextPure'].lower()\n",
    "        sp = re.sub(\"[^a-zA-Z\\s]+\", \"\", sp) # removing extraneous characters\n",
    "        sp = re.sub(\"\\s+\", \" \", sp) # removing extra characters\n",
    "        sp = sp.strip()\n",
    "        sp = sp.split() # splitting into words\n",
    "        \n",
    "        sp = [x for x in sp if x not in stopwords] # strip stopwords\n",
    "        \n",
    "        if False:\n",
    "            tups = set(zip(sp[:-1], sp[1:])) # two-word tuples\n",
    "        elif False:\n",
    "            tups = set( (t1,t2) for t1 in sp for t2 in sp if t1!=t2 )# every two-word pair :)\n",
    "        else:\n",
    "            \n",
    "            tups = set( \"-\".join(sorted(x)) for x in set(zip(sp[:-1], sp[1:]))) # two-word tuples\n",
    "            tups.update( sp ) # one-word tuples\n",
    "            \n",
    "        #print(len(tups),c['contextPure'], \"---\", tups)\n",
    "        \n",
    "        if len(term_whitelist):\n",
    "            tups = [x for x in tups if x in term_whitelist]\n",
    "\n",
    "        # just term count, in case we are using the `basic` mode\n",
    "        for t1 in tups:\n",
    "            # term\n",
    "            cnt((t1,), 't', doc['doi'])\n",
    "\n",
    "            # term year\n",
    "            cnt((doc['year'], t1), 'fy.t', doc['doi'])\n",
    "            \n",
    "        \n",
    "        if mode == 'all':\n",
    "\n",
    "\n",
    "            for cited in c['citations']:\n",
    "                \n",
    "                if use_included_citations_filter and (cited not in included_citations):\n",
    "                    continue\n",
    "                    \n",
    "                # term features\n",
    "                for t1 in tups:\n",
    "                    \n",
    "                    # cited work, tuple\n",
    "                    cnt((cited, t1), 'c.t', doc['doi'])\n",
    "\n",
    "                    # term journal\n",
    "                    cnt((doc['journal'], t1), 'fj.t', doc['doi'])\n",
    "\n",
    "                    if False: # eliminating data I'm not using\n",
    "\n",
    "                        # author loop\n",
    "                        for a in doc['authors']:\n",
    "                            # term author\n",
    "                            cnt((a, t1), 'fa.t', doc['doi'])\n",
    "                            \n",
    "                    if len(term_whitelist): # really don't want to do this too early. wait until it's narrowed down to the 5k\n",
    "                        # term term...\n",
    "                        for t2 in tups:\n",
    "                            # if they intersect each other, continue...\n",
    "                            if len(set(t1).intersection(set(t2))):\n",
    "                                print(\"skip\")\n",
    "                                continue\n",
    "                            print('keep')\n",
    "\n",
    "                            # term term\n",
    "                            cnt((t1,t2), 't.t', doc['doi'])\n",
    "\n",
    "                # author loop\n",
    "                for a in doc['authors']:\n",
    "                    # citation author\n",
    "                    cnt((cited,a), 'c.fa', doc['doi'])\n",
    "\n",
    "                    # year author journal\n",
    "                    cnt((a, doc['journal'], doc['year']), 'fa.fj.fy', doc['doi'])\n",
    "\n",
    "                    # author\n",
    "                    cnt((a,), 'fa', doc['doi'])\n",
    "\n",
    "                # add to counters for citation-citation counts\n",
    "                for cited1 in c['citations']:\n",
    "                    for cited2 in c['citations']:\n",
    "                        if cited1 >= cited2:\n",
    "                            continue\n",
    "\n",
    "                        cnt(( cited1, cited2 ), 'c.c', doc['doi'])\n",
    "                        cnt(( cited1, cited2, doc['year'] ), 'c.c.fy', doc['doi'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016954,
     "end_time": "2020-05-23T00:16:35.019410",
     "exception": false,
     "start_time": "2020-05-23T00:16:35.002456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Master counting cell\n",
    "\n",
    "This cell is **long-running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 620.295613,
     "end_time": "2020-05-23T00:26:55.331978",
     "exception": false,
     "start_time": "2020-05-23T00:16:35.036365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 ... 0 journals... 0 cited works... 0 authors... 0 terms used... 0 skipped citations...\n",
      "Document 1000 ... 35 journals... 4377 cited works... 399 authors... 73236 terms used... 2725 skipped citations...\n",
      "Document 2000 ... 37 journals... 7844 cited works... 799 authors... 130033 terms used... 5080 skipped citations...\n",
      "Citation 15038\n",
      "Term 144061\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dc36c4f24c40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# now that we have all the information we need,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# we simply need to \"count\" this document in a few different ways\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0maccount_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-5233eb90451b>\u001b[0m in \u001b[0;36maccount_for\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#print(sample(list(cnt_doc['t']), 10))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlast_print\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mconsolidate_terms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a7e351f8ae0b>\u001b[0m in \u001b[0;36mconsolidate_terms\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0margst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mto_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margst\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mNUM_TERMS_TO_KEEP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# half should be 2-tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mto_keep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margst\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mNUM_TERMS_TO_KEEP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# half should be 1-tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "total_count = Counter()\n",
    "doc_count = Counter()\n",
    "pair_count = Counter()\n",
    "\n",
    "debug = False\n",
    "\n",
    "for i, (doi, metadata_str, ocr_str) in enumerate( file_iterator(zipfiles) ):\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Document\", i, \"...\", \n",
    "              len(cnt_doc['fj'].keys()), \"journals...\", \n",
    "              len(cnt_doc['c'].keys()), \"cited works...\", \n",
    "              len(cnt_doc['fa'].keys()), \"authors...\",\n",
    "              len(cnt_doc['t'].keys()), \"terms used...\",\n",
    "              citations_skipped, \"skipped citations...\"\n",
    "             )\n",
    "\n",
    "    try:\n",
    "        drep = clean_metadata( doi, metadata_str )\n",
    "        \n",
    "        # sometimes multiple journal names map onto the same journal, for all intents and purposes\n",
    "        if drep['journal'] in journal_map:\n",
    "            drep['journal'] = journal_map[drep['journal']]\n",
    "        \n",
    "        # only include journals in the list \"included_journals\"\n",
    "        if use_included_journals_filter and (drep['journal'] not in included_journals):\n",
    "            continue\n",
    "        \n",
    "        if debug: print(\"got meta\")\n",
    "\n",
    "        if drep['type'] != 'research-article':\n",
    "            continue\n",
    "            \n",
    "        # some types of titles should be immediately ignored\n",
    "        def title_looks_researchy(lt):\n",
    "            lt = lt.lower()\n",
    "            lt = lt.strip()\n",
    "\n",
    "            for x in [\"book review\", 'review essay', 'back matter', 'front matter', 'notes for contributors', 'publication received', 'errata:', 'erratum:']:\n",
    "                if x in lt:\n",
    "                    return False\n",
    "\n",
    "            for x in [\"commentary and debate\", 'erratum', '']:\n",
    "                if x == lt:\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        lt = drep['title'].lower()\n",
    "        if not title_looks_researchy(lt):\n",
    "            continue\n",
    "\n",
    "        # Don't process the document if there are no authors\n",
    "        if not len(drep['authors']):\n",
    "            continue\n",
    "\n",
    "        drep['content'] = get_content_string(ocr_str)\n",
    "        \n",
    "        drep['citations'] = []\n",
    "        \n",
    "        # loop through the matching parentheses in the document\n",
    "        for index, (parenStart, parenContents) in enumerate(getOuterParens(drep['content'])):\n",
    "            \n",
    "            citations = list(citation_iterator(parenContents))\n",
    "            if not len(citations):\n",
    "                continue\n",
    "\n",
    "                \n",
    "            citation = {\n",
    "                \"citations\": citations,\n",
    "                \"contextLeft\": drep['content'][parenStart-400+1:parenStart+1],\n",
    "                \"contextRight\": drep['content'][parenStart + len(parenContents) + 1:parenStart + len(parenContents) + 1 + 100],\n",
    "                \"where\": parenStart\n",
    "            }\n",
    "\n",
    "\n",
    "            # cut off any stuff before the first space\n",
    "            first_break_left = re.search(r\"[\\s\\.!\\?]+\", citation['contextLeft'])\n",
    "            if first_break_left is not None:\n",
    "                clean_start_left = citation['contextLeft'][first_break_left.end():]\n",
    "            else:\n",
    "                clean_start_left = citation['contextLeft']\n",
    "\n",
    "            # cut off any stuff after the last space\n",
    "            last_break_right = list(re.finditer(r\"[\\s\\.!\\?]+\", citation['contextRight']))\n",
    "            if len(last_break_right):\n",
    "                clean_end_right = citation['contextRight'][:last_break_right[-1].start()]\n",
    "            else:\n",
    "                clean_end_right = citation['contextRight']\n",
    "\n",
    "            # we don't want anything more than a sentence\n",
    "            \n",
    "            sentence_left = sent_tokenize(clean_start_left)\n",
    "            if len(sentence_left):\n",
    "                sentence_left = sentence_left[-1]\n",
    "            else:\n",
    "                sentence_left = \"\"\n",
    "\n",
    "            sentence_right = sent_tokenize(clean_end_right)[0]\n",
    "            if len(sentence_right):\n",
    "                sentence_right = sentence_right[0]\n",
    "            else:\n",
    "                sentence_right = \"\"\n",
    "\n",
    "            # finally, strip the parentheses from the string\n",
    "            sentence_left = sentence_left[:-1]\n",
    "            sentence_right = sentence_right[1:]\n",
    "\n",
    "            # add the thing in context\n",
    "            full = sentence_left + \"<CITATION>\" + sentence_right\n",
    "\n",
    "            citation['contextPure'] = sentence_left\n",
    "            #print(full)\n",
    "\n",
    "            drep['citations'].append(citation)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # now that we have all the information we need,\n",
    "        # we simply need to \"count\" this document in a few different ways\n",
    "        account_for(drep)\n",
    "\n",
    "\n",
    "    except ParseError as e:\n",
    "        print(\"parse error...\", e.args, doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cnt_doc['t'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in cnt_doc['t'] if not '-' in x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(list(cnt_doc['t'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,v in cnt_doc.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Save the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_cnt(\"%s.doc\"%database_name, cnt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_cnt(\"%s.ind\"%database_name, cnt_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "G:\\My Drive\\projects\\qualitative analysis of literature\\post 5-12-2020\\git repository _ citation-deaths\\knowknow\\creating variables\\jstor counter (cnt).ipynb",
   "output_path": "G:\\My Drive\\projects\\qualitative analysis of literature\\post 5-12-2020\\git repository _ citation-deaths\\knowknow\\creating variables\\jstor counter (cnt).ipynb",
   "parameters": {},
   "start_time": "2020-05-23T00:16:31.253561",
   "version": "2.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
