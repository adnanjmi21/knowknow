{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.986605,
     "end_time": "2020-05-23T00:16:33.493830",
     "exception": false,
     "start_time": "2020-05-23T00:16:32.507225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append(_dh[0].split(\"knowknow\")[0])\n",
    "from knowknow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Counting coocurrences\n",
       "\n",
       "Cultural phenomena are rich in meaning and context. Moreover, the meaning and context are what we care about, so stripping that would be a disservice. \"Consider Geertz:\"\n",
       "> Not only is the semantic structure of the figure a good deal more complex than it appears on the surface, but an analysis of that structure forces one into tracing a multiplicity of referential connections between it and social reality, so that the final picture is one of a configuration of dissimilar meanings out of whose interworking both the expressive power and the rhetorical force of the final symbol derive. (Geertz [1955] 1973, Chapter 8 Ideology as a Cultural System, p. 213)\n",
       "\n",
       "The way people understanding their world shape their action, and understandings are heterogeneous in any community, woven into a complex web of interacting pieces and parts. Understandings are constantly evolving, shifting with every conversation or Breaking News. Any quantitative technique for studying meaning must be able to capture the relational structure of cultural objects, their temporal dynamics, or it cannot be meaning.\n",
       "\n",
       "These considerations motivate how I have designed the data structure and code for this project. My attention to \"cooccurrences\" in what follows is an application of Levi Martin and Lee's (2018) formal approach to meaning. They develop the symbolic formalism I use below, as well as showing several general analytic strategies for inductive, ground-up meaning-making from count data. This approach is quite general, useful for many applications.\n",
       "\n",
       "The process is rather simple, I count cooccurrences between various attributes. For each document, for each citation in that document, I increment a dozen counters, depending on attributes of the citation, paper, journal, or author. This counting process is done once, and can be used as a compressed form of the dataset for all further analyses. In the terminology of Levi Martin and Lee, I am constructing \"hypergraphs\", and I will use their notation in what follows. For example $[c*fy]$ indicates the dataset which maps from $(c, fy) \\to count$.\n",
       "$c$ is the name of the cited work. $fy$ is the publication year of the article which made the citation. $count$ is the number of citations which are at the intersection of these properties.\n",
       "\n",
       "+ $[c]$ the number of citations each document receives\n",
       "+ $[c*fj]$ the number of citations each document receives from each journal's articles\n",
       "+ $[c*fy]$ the number of citations each document receives from each year's articles\n",
       "+ $[fj]$ the number of citations from each journal\n",
       "+ $[fj*fy]$ the number of citations in each journal in each year\n",
       "+ $[t]$ cited term total counts\n",
       "+ $[fy*t]$ cited term time series\n",
       "+ term cooccurrence with citation and journal ($[c*t]$ and [fj*t]$)\n",
       "+ \"author\" counts, the number of citations by each author ($[a]$ $[a*c]$ $[a*j*y]$)\n",
       "+ [c*c]$, the cooccurrence network between citations\n",
       "+ the death of citations can be studied using the $[c*fy]$ hypergraph\n",
       "+ $[c*fj*t]$ could be used for analyzing differential associations of $c$ to $t$ across publication venues\n",
       "+ $[ta*ta]$, $[fa*fa]$, $[t*t]$ and $[c*c]$ open the door to network-scientific methods\n",
       "\n",
       "\n",
       "\n",
       "# References\n",
       "\n",
       "\n",
       "\n",
       "+ Martin, John Levi, and Monica Lee. 2018. “A Formal Approach to Meaning.” Poetics 68(February):10–17.\n",
       "+ Geertz, Clifford. 1973. The Interpretation of Cultures. New York: Basic Books, Inc."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showdocs(\"counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017952,
     "end_time": "2020-05-23T00:16:33.530698",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.512746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# README\n",
    "\n",
    "First, you need to get some data. In accordance with JSTOR's usage policies, I **do not provide any full-text data**. And that's the data you need to use this notebook.\n",
    "You can obtain your own data by requesting full OCR data packages through JSTOR's [Data for Research](https://www.jstor.org/dfr/) initiative. \n",
    "\n",
    "Make sure to read carefully through \"User Settings.\" Set the appropriate settings, and run the entire notebook.\n",
    "\n",
    "This will create a new \"database\" of counts, which can be recalled by running `my_counts = get_cnt( '<DB_NAME_HERE>' )`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015957,
     "end_time": "2020-05-23T00:16:33.563610",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.547653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# User Settings\n",
    "\n",
    "`database_name` is the name you choose for the final dataset of counts\n",
    "\n",
    "`zipdir` is the directory which contains the `.zip` files JSTOR provides to you (not included)\n",
    "\n",
    "`mode` choose between \"basic\" and \"all\" mode\n",
    "\n",
    "1. \"basic\" mode\n",
    "    + this mode is not typically faster than `everything`, but it does reduce RAM overhead\n",
    "        + on ~200k articles the running counters take up more than 16GB RAM\n",
    "        + to counter this, I first run simple statistics, then rerun this notebook again, filtering based on the descriptive statistics\n",
    "    + includes `c` counts, the number of citations each document receives\n",
    "    + includes `c.fj` counts, the number of citations each document receives from each journal's articles\n",
    "    + includes `c.fy` counts, the number of citations each document receives from each year's articles\n",
    "    + includes `fj` counts, the number of citations from each journal\n",
    "    + includes `fj.fy` counts, the number of citations in each journal in each year\n",
    "    + includes `t` `fy.t` counts, for term time series and filtering\n",
    "\n",
    "2. \"all\" mode\n",
    "    + you must run this if you want to run all analyses included in this project\n",
    "    + includes all counts from `basic` mode\n",
    "    + includes term cooccurrence with citation and journal (`c.t` `fj.t`)\n",
    "    + includes \"author\" counts, the number of citations by each author (`a` `a.c` `a.j.y`)\n",
    "    + includes `c.c`, the cooccurrence network between citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2020-05-23T00:16:33.603504",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.581562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "database_name = 'sociology-jstor-basicall'\n",
    "zipdir = 'G:/My Drive/projects/qualitative analysis of literature/pre 5-12-2020/003 process JSTOR output/RaW dAtA/'\n",
    "mode = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016955,
     "end_time": "2020-05-23T00:16:33.638410",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.621455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I use citation and journal filters while counting. \n",
    "This filtering is important when working with large datasets. You can run the \"trend summaries/cysum\" on a `basic` database, and use the variable it automatically generates, `\"<DBNAME>.included_citations\"` to modify which citations to use when computing the `all` database.\n",
    "\n",
    "In most cases, it's best to set `use_included_citations_filter` and `use_included_journals_filter` both to `False` the first time you run this notebook on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.051889,
     "end_time": "2020-05-23T00:16:33.707253",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.655364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_included_citations_filter = True\n",
    "use_included_journals_filter = True\n",
    "\n",
    "# not necessary if you're not filtering based on citations and journals pre-count\n",
    "included_citations = load_variable(\"sociology-jstor.included_citations\")\n",
    "included_journals = ['Acta Sociologica', 'Administrative Science Quarterly', 'American Journal of Political Science', 'American Journal of Sociology', 'American Sociological Review', 'Annual Review of Sociology', 'BMS: Bulletin of Sociological Methodology / Bulletin de Méthodologie Sociologique', 'Berkeley Journal of Sociology', 'Contemporary Sociology', 'European Sociological Review', 'Hitotsubashi Journal of Social Studies', 'Humboldt Journal of Social Relations', 'International Journal of Sociology', 'International Journal of Sociology of the Family', 'International Review of Modern Sociology', 'Journal for the Scientific Study of Religion', 'Journal of Health and Social Behavior', 'Journal of Marriage and Family', 'Language in Society', 'Michigan Sociological Review', 'Polish Sociological Review', 'Review of Religious Research', 'Social Forces', 'Social Indicators Research', 'Social Problems', 'Social Psychology Quarterly', 'Sociological Bulletin', 'Sociological Focus', 'Sociological Forum', 'Sociological Methodology', 'Sociological Perspectives', 'Sociological Theory', 'Sociology', 'Sociology of Education', 'Sociology of Religion', 'Symbolic Interaction', 'The American Sociologist', 'The British Journal of Sociology', 'The Canadian Journal of Sociology', 'The Sociological Quarterly', 'Theory and Society']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043911,
     "end_time": "2020-05-23T00:16:33.768096",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.724185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Terms are iteratively pruned. After `CONSOLIDATE_EVERY_N_CITS` citations are counted, the algorithm will keep only the top `NUM_TERMS_TO_KEEP` terms, blacklisting the rest and not counting them anymore. This doesn't hurt the dataset, but dramatically reduces the RAM overhead and the size of the final dataset on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.019947,
     "end_time": "2020-05-23T00:16:33.804998",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.785051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONSOLIDATE_TERMS = True\n",
    "\n",
    "NUM_TERMS_TO_KEEP = 5000\n",
    "\n",
    "CONSOLIDATE_EVERY_N_CITS = NUM_TERMS_TO_KEEP*3\n",
    "#CONSOLIDATE_EVERY_N_CITS = 1000\n",
    "\n",
    "NPERYEAR = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022938,
     "end_time": "2020-05-23T00:16:33.844891",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.821953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's also convenient to be able to rename various entities. There were a few different names for the Canadian Journal of Sociology. If you want to filter on something other than journals, you'll have to modify the code and add this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2020-05-23T00:16:33.884785",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.862843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "journal_map = {} # default\n",
    "journal_map = {\n",
    "    \"Canadian Journal of Sociology / Cahiers canadiens de sociologie\": 'The Canadian Journal of Sociology',\n",
    "    \"The Canadian Journal of Sociology / Cahiers canadiens de\\n                sociologie\": 'The Canadian Journal of Sociology',\n",
    "    'The Canadian Journal of Sociology / Cahiers canadiens de sociologie': 'The Canadian Journal of Sociology'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017952,
     "end_time": "2020-05-23T00:16:33.918693",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.900741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.323136,
     "end_time": "2020-05-23T00:16:34.258784",
     "exception": false,
     "start_time": "2020-05-23T00:16:33.935648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "from nltk import sent_tokenize\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./creating variables/'))\n",
    "\n",
    "# library functions for cleaning and extracting in-text citations from OCR\n",
    "from cnt_cooc_jstor_lib import (\n",
    "    citation_iterator, getOuterParens, \n",
    "    Document, ParseError, \n",
    "    clean_metadata\n",
    ")\n",
    "\n",
    "# XML parser\n",
    "from lxml.etree import _ElementTree as ElementTree\n",
    "from lxml import etree\n",
    "recovering_parser = etree.XMLParser(recover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.022939,
     "end_time": "2020-05-23T00:16:34.301669",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.278730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting ready for term counting\n",
    "from nltk.corpus import stopwords as sw\n",
    "stopwords = set(sw.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.022939,
     "end_time": "2020-05-23T00:16:34.361509",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.338570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zipfiles = list(Path(zipdir).glob(\"*.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018938,
     "end_time": "2020-05-23T00:16:34.398410",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.379472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01697,
     "end_time": "2020-05-23T00:16:34.433332",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.416362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following helper function `file_iterator` iterates through all documents inside a list of zipfiles\n",
    "\n",
    "Each iteration returns:\n",
    "1. the document DOI\n",
    "2. the metadata file contents\n",
    "3. the ocr file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.023937,
     "end_time": "2020-05-23T00:16:34.475220",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.451283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getname(x):\n",
    "    x = x.split(\"/\")[-1]\n",
    "    x = re.sub(r'(\\.xml|\\.txt)','',x)\n",
    "    return x\n",
    "\n",
    "def file_iterator(zipfiles):\n",
    "    from random import shuffle\n",
    "    \n",
    "    all_files = []\n",
    "    for zf in zipfiles:\n",
    "        archive = ZipFile(zf, 'r')\n",
    "        files = archive.namelist()\n",
    "        names = list(set(getname(x) for x in files))\n",
    "        \n",
    "        all_files += [(archive,name) for name in names]\n",
    "        \n",
    "    shuffle(all_files)\n",
    "        \n",
    "    for archive, name in all_files:\n",
    "        try:\n",
    "            yield(\n",
    "                name.split(\"-\")[-1].replace(\"_\", \"/\"),\n",
    "                archive.read(\"metadata/%s.xml\" % name),\n",
    "                archive.read(\"ocr/%s.txt\" % name).decode('utf8')\n",
    "            )\n",
    "        except KeyError: # some very few articles don't have both\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017951,
     "end_time": "2020-05-23T00:16:34.511128",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.493177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`get_page_strings` takes the string contents of an XML file produced by JSTOR. The XML file in question represents the text of a given article. This function cleans the text for OCR peculiarities, and splits the document into pages for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.024942,
     "end_time": "2020-05-23T00:16:34.553025",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.528083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basic_ocr_cleaning(x):\n",
    "    # remove multiple spaces in a row\n",
    "    x = re.sub(r\" +\", ' ', str(x))\n",
    "    # remove hyphenations [NOTE this should be updated, with respect to header and footer across pages...]\n",
    "    x = re.sub(r\"([A-Za-z]+)-\\s+([A-Za-z]+)\", \"\\g<1>\\g<2>\", x)\n",
    "    \n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "def get_content_string(ocr_string):\n",
    "    docXml = etree.fromstring(ocr_string, parser=recovering_parser)\n",
    "    pages = docXml.findall(\".//page\")\n",
    "\n",
    "    page_strings = []\n",
    "    for p in pages:\n",
    "        if p.text is None:\n",
    "            continue\n",
    "        page_strings.append(p.text)\n",
    "\n",
    "    secs = docXml.findall(\".//sec\")\n",
    "\n",
    "    for s in secs:\n",
    "        if s.text is None:\n",
    "            continue\n",
    "        if s.text.strip() == '':\n",
    "            try_another = etree.tostring(s, encoding='utf8', method='text').decode(\"utf8\").strip()\n",
    "            #print(try_another)\n",
    "            if try_another == '':\n",
    "                continue\n",
    "\n",
    "            page_strings.append(try_another)\n",
    "        else:\n",
    "            page_strings.append(s.text.strip())\n",
    "\n",
    "    return basic_ocr_cleaning( \"\\n\\n\".join(page_strings) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.240891,
     "end_time": "2020-05-23T00:16:34.810862",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.569971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`consolidate terms` was built to eliminate all terms which are not in the top `NUM_TERMS_TO_KEEP`.\n",
    "This is done by sorting `fromyear-term`, or `fy.t` counts in descending order. The top entry here is the term-year pair which accumulated the most appearances in citation contexts. I take the top 1000 `t`'s in this sorted list and preserve them, and blacklist the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.02992,
     "end_time": "2020-05-23T00:16:34.859731",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.829811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "term_whitelist = set()\n",
    "\n",
    "def consolidate_terms():\n",
    "    global term_whitelist, CONSOLIDATION_CUTOFF\n",
    "    \n",
    "\n",
    "    have_now = set(cnt_doc['t'])\n",
    "    # this is where the filtering occurs\n",
    "    \n",
    "    to_keep = set()\n",
    "    if True:\n",
    "        \n",
    "        # takes terms based on the maximum number I can take...\n",
    "        terms = list(cnt_doc['t'].keys())\n",
    "        counts = np.array([cnt_doc['t'][k] for k in terms])\n",
    "        argst = list(reversed(np.argsort(counts)))\n",
    "        \n",
    "        to_keep = [terms[i] for i in argst if '-' in terms[i][0]][:NUM_TERMS_TO_KEEP//2] # half should be 2-tuples\n",
    "        to_keep += [terms[i] for i in argst if not '-' in terms[i][0]][:NUM_TERMS_TO_KEEP//2] # half should be 1-tuples\n",
    "        \n",
    "        to_remove = have_now.difference(to_keep)\n",
    "        to_remove = set(\"-\".join(x) for x in to_remove)\n",
    "            \n",
    "    \n",
    "    if False:\n",
    "        # takes the top 5000 terms in terms of yearly count\n",
    "        sort_them = sorted(cnt_doc['fy.t'], key=lambda x: -cnt_doc['fy.t'][x])\n",
    "        to_keep = defaultdict(set)\n",
    "        \n",
    "        i = 0\n",
    "        while not len(to_keep) or (\n",
    "            min(len(x) for x in to_keep.values()) < NPERYEAR and \n",
    "            i < len(sort_them)\n",
    "        ):\n",
    "            # adds the term to the year set, if it's not already \"full\"\n",
    "            me = sort_them[i]\n",
    "            me_fy, me_t = me\n",
    "            \n",
    "            # eventually, we don't count it :P\n",
    "            if cnt_doc['t'][me_t] < CONSOLIDATION_CUTOFF:\n",
    "                break\n",
    "            \n",
    "            if len(to_keep[me_fy]) < NPERYEAR:\n",
    "                to_keep[me_fy].add(me_t) \n",
    "            i += 1\n",
    "            \n",
    "        if False: # useful for debugging\n",
    "            print({\n",
    "                k: len(v)\n",
    "                for k,v in to_keep.items()\n",
    "            })\n",
    "            \n",
    "        to_keep = set(chain.from_iterable(x for x in to_keep.values()))\n",
    "        to_remove = have_now.difference(to_keep)\n",
    "    \n",
    "    \n",
    "    # so that we never log counts for these again:\n",
    "    term_whitelist.update(to_keep)\n",
    "\n",
    "    # the rest of the code is pruning all other term counts for this term in memory\n",
    "    print(\"consolidating... removing\", len(to_remove), 'e.g.', sample(to_remove,5))\n",
    "    \n",
    "    to_prune = ['t','fy.t','fj.t','c.t']\n",
    "    for tp in to_prune:\n",
    "        \n",
    "        whichT = tp.split(\".\").index('t') # this checks where 't' is in the name of the variable (first or second?)\n",
    "\n",
    "        print(\"pruning '%s'...\" % tp)\n",
    "\n",
    "        tydels = [x for x in cnt_doc[tp] if x[ whichT ] in to_remove]\n",
    "            \n",
    "        print(\"old size:\", len(cnt_doc[tp]))\n",
    "        for tr in tydels:\n",
    "            del cnt_doc[tp][tr]\n",
    "            del cnt_ind[tp][tr]\n",
    "        print(\"new size:\", len(cnt_doc[tp]))\n",
    "        \n",
    "    \n",
    "    print(\"final terms: \", \", \".join( sample(list(\"-\".join(list(x)) for x in cnt_doc['t']), 200) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016954,
     "end_time": "2020-05-23T00:16:34.894637",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.877683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Counting algorithm\n",
    "\n",
    "The following cells contain the counting function, which accounts for a document in various ways.\n",
    "This function should be relatively simple to extend, if you want to count other combinations, or different attributes altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.021974,
     "end_time": "2020-05-23T00:16:34.933640",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.911666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt_ind = defaultdict(lambda:defaultdict(int))\n",
    "track_doc = defaultdict(lambda:defaultdict(set))\n",
    "cnt_doc = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "def cnt(term, space, doc):\n",
    "    # it's a set, yo\n",
    "    track_doc[space][term].add(doc)\n",
    "    # update cnt_doc\n",
    "    cnt_doc[space][term] = len(track_doc[space][term])\n",
    "    # update ind count\n",
    "    cnt_ind[space][term] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.032995,
     "end_time": "2020-05-23T00:16:34.984587",
     "exception": false,
     "start_time": "2020-05-23T00:16:34.951592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cits = 0\n",
    "last_print = 0\n",
    "citations_skipped = 0\n",
    "\n",
    "def account_for(doc):\n",
    "    global cits, last_print, mode, citations_skipped\n",
    "    \n",
    "    # consolidating \"terms\" counter as I go, to limit RAM overhead\n",
    "    # I'm only interested in the most common 1000\n",
    "    if CONSOLIDATE_TERMS and \\\n",
    "            not len(term_whitelist) and \\\n",
    "            cits - last_print > CONSOLIDATE_EVERY_N_CITS:\n",
    "        print(\"Citation %s\" % cits)\n",
    "        print(\"Term %s\" % len(cnt_doc['t']))\n",
    "        #print(sample(list(cnt_doc['t']), 10))\n",
    "        last_print = cits\n",
    "        consolidate_terms()\n",
    "\n",
    "\n",
    "    if 'citations' not in doc or not len(doc['citations']):\n",
    "        #print(\"No citations\", doc['doi'])\n",
    "        return\n",
    "\n",
    "    for c in doc['citations']:\n",
    "        if 'contextPure' not in c:\n",
    "            raise Exception(\"no contextPure...\")\n",
    "\n",
    "\n",
    "\n",
    "        for cited in c['citations']:\n",
    "            \n",
    "            if use_included_citations_filter and (cited not in included_citations):\n",
    "                citations_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            cits += 1\n",
    "            cnt(doc['year'], 'fy', doc['doi'])\n",
    "\n",
    "            # citation\n",
    "            cnt(cited, 'c', doc['doi'])\n",
    "\n",
    "            # journal\n",
    "            cnt(doc['journal'], 'fj', doc['doi'])\n",
    "\n",
    "            # journal year\n",
    "            cnt((doc['journal'], doc['year']), 'fj.fy', doc['doi'])\n",
    "\n",
    "            # citation journal\n",
    "            cnt((cited, doc['journal']), 'c.fj', doc['doi'])\n",
    "\n",
    "            # citation year\n",
    "            cnt((cited, doc['year']), 'c.fy', doc['doi'])\n",
    "\n",
    "            \n",
    "        # constructing the tuples set :)\n",
    "        sp = c['contextPure'].lower()\n",
    "        sp = re.sub(\"[^a-zA-Z\\s]+\", \"\", sp) # removing extraneous characters\n",
    "        sp = re.sub(\"\\s+\", \" \", sp) # removing extra characters\n",
    "        sp = sp.strip()\n",
    "        sp = sp.split() # splitting into words\n",
    "        \n",
    "        sp = [x for x in sp if x not in stopwords] # strip stopwords\n",
    "        \n",
    "        if False:\n",
    "            tups = set(zip(sp[:-1], sp[1:])) # two-word tuples\n",
    "        elif False:\n",
    "            tups = set( (t1,t2) for t1 in sp for t2 in sp if t1!=t2 )# every two-word pair :)\n",
    "        else:\n",
    "            \n",
    "            tups = set( \"-\".join(sorted(x)) for x in set(zip(sp[:-1], sp[1:]))) # two-word tuples\n",
    "            tups.update( sp ) # one-word tuples\n",
    "            \n",
    "        #print(len(tups),c['contextPure'], \"---\", tups)\n",
    "        \n",
    "        if len(term_whitelist):\n",
    "            tups = [x for x in tups if x in term_whitelist]\n",
    "\n",
    "        # just term count, in case we are using the `basic` mode\n",
    "        for t1 in tups:\n",
    "            # term\n",
    "            cnt((t1,), 't', doc['doi'])\n",
    "\n",
    "            # term year\n",
    "            cnt((doc['year'], t1), 'fy.t', doc['doi'])\n",
    "            \n",
    "        \n",
    "        if mode == 'all':\n",
    "\n",
    "\n",
    "            for cited in c['citations']:\n",
    "                \n",
    "                if use_included_citations_filter and (cited not in included_citations):\n",
    "                    continue\n",
    "                    \n",
    "                # term features\n",
    "                for t1 in tups:\n",
    "                    \n",
    "                    # cited work, tuple\n",
    "                    cnt((cited, t1), 'c.t', doc['doi'])\n",
    "\n",
    "                    # term journal\n",
    "                    cnt((doc['journal'], t1), 'fj.t', doc['doi'])\n",
    "\n",
    "                    if False: # eliminating data I'm not using\n",
    "\n",
    "                        # author loop\n",
    "                        for a in doc['authors']:\n",
    "                            # term author\n",
    "                            cnt((a, t1), 'fa.t', doc['doi'])\n",
    "                            \n",
    "                    if len(term_whitelist): # really don't want to do this too early. wait until it's narrowed down to the 5k\n",
    "                        # term term...\n",
    "                        for t2 in tups:\n",
    "                            # if they intersect each other, continue...\n",
    "                            if len(set(t1).intersection(set(t2))):\n",
    "                                print(\"skip\")\n",
    "                                continue\n",
    "                            print('keep')\n",
    "\n",
    "                            # term term\n",
    "                            cnt((t1,t2), 't.t', doc['doi'])\n",
    "\n",
    "                # author loop\n",
    "                for a in doc['authors']:\n",
    "                    # citation author\n",
    "                    cnt((cited,a), 'c.fa', doc['doi'])\n",
    "\n",
    "                    # year author journal\n",
    "                    cnt((a, doc['journal'], doc['year']), 'fa.fj.fy', doc['doi'])\n",
    "\n",
    "                    # author\n",
    "                    cnt((a,), 'fa', doc['doi'])\n",
    "\n",
    "                # add to counters for citation-citation counts\n",
    "                for cited1 in c['citations']:\n",
    "                    for cited2 in c['citations']:\n",
    "                        if cited1 >= cited2:\n",
    "                            continue\n",
    "\n",
    "                        cnt(( cited1, cited2 ), 'c.c', doc['doi'])\n",
    "                        cnt(( cited1, cited2, doc['year'] ), 'c.c.fy', doc['doi'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016954,
     "end_time": "2020-05-23T00:16:35.019410",
     "exception": false,
     "start_time": "2020-05-23T00:16:35.002456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Master counting cell\n",
    "\n",
    "This cell is **long-running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 620.295613,
     "end_time": "2020-05-23T00:26:55.331978",
     "exception": false,
     "start_time": "2020-05-23T00:16:35.036365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 ... 0 journals... 0 cited works... 0 authors... 0 terms used... 0 skipped citations...\n",
      "Document 1000 ... 38 journals... 4300 cited works... 343 authors... 71963 terms used... 2513 skipped citations...\n",
      "Document 2000 ... 41 journals... 8453 cited works... 771 authors... 137978 terms used... 5187 skipped citations...\n",
      "Citation 15016\n",
      "Term 142632\n",
      "consolidating... removing 137632 e.g. ['macrosociology', 'dangerous-sell', 'benefits-foregone', 'scholars-today', 'context-students']\n",
      "pruning 't'...\n",
      "old size: 142632\n",
      "new size: 5000\n",
      "pruning 'fy.t'...\n",
      "old size: 215606\n",
      "new size: 56127\n",
      "pruning 'fj.t'...\n",
      "old size: 164456\n",
      "new size: 40120\n",
      "pruning 'c.t'...\n",
      "old size: 366998\n",
      "new size: 154241\n",
      "final terms:  initially, five-one, beginning, diversity-within, origin, adult-children, may-one, estimates, concern-major, beliefs-religious, first-time, waves, highlighted, linked, constructed-socially, many, among-college, divorce-rate, interests, based-different, generally-studies, inherent, despite, briar-piliavin, east-middle, longer, ethnic-groups, significantly, majority-vast, political-support, failed, crime-reports, industrial-modern, likely, experiences-may, congress, replaced, normally, pressure, recognized-social, due-sample, successful, great, surrounding, current, solely, body-large, census-using, attempted, suicide, aspect-one, regulations-rules, representation, drug, number-volume, place-take, becomes-less, factor-important, interpersonal-relationships, eg-see, estimate, control-sense, distance-social, consistent-results, apparent, capital-social, degrees, economic-social, reference, autonomy-personal, berger, ensure, conceptualization, search, serious, conflicting, sources, rural, december-forces, reality-social, areas-rural, also-argued, health-services, family-study, patients, living-standards, university, historical-research, equality-gender, underlying, blacks, either, continuing, outcomes-policy, contingent-upon, theory, education-levels, observe, however-increasingly, measures, identity-personal, personality-structure, alone, family-patterns, whatever, definitions, found-positive, growth-rates, component-important, validity, sufficient, providing, house, economic-expansion, predicts, versions, spatial, better-educated, attachments-emotional, others-whereas, component, lies, concluded, greater, indicated, poverty, many-reasons, membership, distinct, van, contribution, whitecollar-workers, four-three, constituent-elements, lines, evidence-little, eg-race, beliefs, make, role-theory, assimilation-spatial, shared, transactions, data-national, homogeneous, japanese, also-see, process, rights-womens, explain-help, welfare, effect-social, abuse-child, stratification-system, head, number-small, critique, association, regulations, found-little, tended, social-understanding, longterm, lay, labor-organized, higher-percentage, review, reduce, clinical-studies, examining, empirical-many, disadvantaged, environment-home, white-women, values, couples-married, prospects, light, support, effects-health, gain, compared, criticized, animal-studies, group-small, scholars-several, like, include, furthermore-studies, disciplines-including, political-science, social-within, color, changes-positive, methods-research, achieved, science-sociology, systematically, late-th, equal\n",
      "Document 3000 ... 41 journals... 11788 cited works... 1151 authors... 5000 terms used... 7352 skipped citations...\n",
      "Document 4000 ... 41 journals... 15537 cited works... 1537 authors... 5000 terms used... 9954 skipped citations...\n",
      "Document 5000 ... 41 journals... 18416 cited works... 1870 authors... 5000 terms used... 12120 skipped citations...\n",
      "Document 6000 ... 41 journals... 21585 cited works... 2226 authors... 5000 terms used... 15008 skipped citations...\n",
      "Document 7000 ... 41 journals... 24145 cited works... 2556 authors... 5000 terms used... 17507 skipped citations...\n",
      "Document 8000 ... 41 journals... 26878 cited works... 2894 authors... 5000 terms used... 19938 skipped citations...\n",
      "Document 9000 ... 41 journals... 29366 cited works... 3236 authors... 5000 terms used... 22260 skipped citations...\n",
      "Document 10000 ... 41 journals... 31774 cited works... 3529 authors... 5000 terms used... 24816 skipped citations...\n",
      "Document 11000 ... 41 journals... 34288 cited works... 3862 authors... 5000 terms used... 27130 skipped citations...\n",
      "Document 12000 ... 41 journals... 36370 cited works... 4205 authors... 5000 terms used... 29193 skipped citations...\n",
      "Document 13000 ... 41 journals... 38714 cited works... 4510 authors... 5000 terms used... 31851 skipped citations...\n",
      "Document 14000 ... 41 journals... 40877 cited works... 4787 authors... 5000 terms used... 34361 skipped citations...\n",
      "Document 15000 ... 41 journals... 43005 cited works... 5091 authors... 5000 terms used... 36549 skipped citations...\n",
      "Document 16000 ... 41 journals... 45013 cited works... 5389 authors... 5000 terms used... 38749 skipped citations...\n",
      "Document 17000 ... 41 journals... 47347 cited works... 5694 authors... 5000 terms used... 41446 skipped citations...\n",
      "Document 18000 ... 41 journals... 49546 cited works... 5981 authors... 5000 terms used... 44003 skipped citations...\n",
      "Document 19000 ... 41 journals... 51536 cited works... 6282 authors... 5000 terms used... 46731 skipped citations...\n",
      "Document 20000 ... 41 journals... 53373 cited works... 6581 authors... 5000 terms used... 49422 skipped citations...\n",
      "Document 21000 ... 41 journals... 55358 cited works... 6897 authors... 5000 terms used... 52390 skipped citations...\n",
      "Document 22000 ... 41 journals... 57111 cited works... 7167 authors... 5000 terms used... 54851 skipped citations...\n",
      "Document 23000 ... 41 journals... 58746 cited works... 7446 authors... 5000 terms used... 57766 skipped citations...\n",
      "Document 24000 ... 41 journals... 60306 cited works... 7727 authors... 5000 terms used... 60090 skipped citations...\n",
      "Document 25000 ... 41 journals... 62110 cited works... 8010 authors... 5000 terms used... 62462 skipped citations...\n",
      "Document 26000 ... 41 journals... 63708 cited works... 8270 authors... 5000 terms used... 65165 skipped citations...\n",
      "Document 27000 ... 41 journals... 65295 cited works... 8533 authors... 5000 terms used... 67686 skipped citations...\n",
      "parse error... ('No valid year found',) 10.2307/26650789\n",
      "Document 28000 ... 41 journals... 67123 cited works... 8822 authors... 5000 terms used... 70619 skipped citations...\n",
      "Document 29000 ... 41 journals... 68410 cited works... 9064 authors... 5000 terms used... 72902 skipped citations...\n",
      "Document 30000 ... 41 journals... 69859 cited works... 9359 authors... 5000 terms used... 75007 skipped citations...\n",
      "Document 31000 ... 41 journals... 71281 cited works... 9613 authors... 5000 terms used... 77733 skipped citations...\n",
      "Document 32000 ... 41 journals... 72596 cited works... 9862 authors... 5000 terms used... 80153 skipped citations...\n",
      "Document 33000 ... 41 journals... 74178 cited works... 10137 authors... 5000 terms used... 83469 skipped citations...\n",
      "Document 34000 ... 41 journals... 75439 cited works... 10366 authors... 5000 terms used... 86080 skipped citations...\n",
      "Document 35000 ... 41 journals... 77018 cited works... 10675 authors... 5000 terms used... 88989 skipped citations...\n",
      "Document 36000 ... 41 journals... 78337 cited works... 10909 authors... 5000 terms used... 91837 skipped citations...\n",
      "Document 37000 ... 41 journals... 79593 cited works... 11150 authors... 5000 terms used... 94422 skipped citations...\n",
      "Document 38000 ... 41 journals... 80918 cited works... 11411 authors... 5000 terms used... 97014 skipped citations...\n",
      "Document 39000 ... 41 journals... 82007 cited works... 11634 authors... 5000 terms used... 99155 skipped citations...\n",
      "Document 40000 ... 41 journals... 83204 cited works... 11862 authors... 5000 terms used... 102057 skipped citations...\n",
      "Document 41000 ... 41 journals... 84439 cited works... 12100 authors... 5000 terms used... 104683 skipped citations...\n",
      "Document 42000 ... 41 journals... 85601 cited works... 12360 authors... 5000 terms used... 107151 skipped citations...\n",
      "Document 43000 ... 41 journals... 86773 cited works... 12611 authors... 5000 terms used... 109969 skipped citations...\n",
      "Document 44000 ... 41 journals... 87925 cited works... 12825 authors... 5000 terms used... 112714 skipped citations...\n",
      "Document 45000 ... 41 journals... 88929 cited works... 13053 authors... 5000 terms used... 115188 skipped citations...\n",
      "Document 46000 ... 41 journals... 89876 cited works... 13278 authors... 5000 terms used... 117570 skipped citations...\n",
      "Document 47000 ... 41 journals... 90948 cited works... 13510 authors... 5000 terms used... 119936 skipped citations...\n",
      "Document 48000 ... 41 journals... 91994 cited works... 13737 authors... 5000 terms used... 122379 skipped citations...\n",
      "Document 49000 ... 41 journals... 92865 cited works... 13950 authors... 5000 terms used... 124652 skipped citations...\n",
      "Document 50000 ... 41 journals... 94013 cited works... 14196 authors... 5000 terms used... 127435 skipped citations...\n",
      "Document 51000 ... 41 journals... 94824 cited works... 14416 authors... 5000 terms used... 129472 skipped citations...\n",
      "Document 52000 ... 41 journals... 95855 cited works... 14630 authors... 5000 terms used... 132121 skipped citations...\n",
      "Document 53000 ... 41 journals... 96835 cited works... 14814 authors... 5000 terms used... 134671 skipped citations...\n",
      "Document 54000 ... 41 journals... 97693 cited works... 15024 authors... 5000 terms used... 136964 skipped citations...\n",
      "Document 55000 ... 41 journals... 98619 cited works... 15241 authors... 5000 terms used... 139381 skipped citations...\n",
      "Document 56000 ... 41 journals... 99620 cited works... 15489 authors... 5000 terms used... 141799 skipped citations...\n",
      "Document 57000 ... 41 journals... 100505 cited works... 15698 authors... 5000 terms used... 144171 skipped citations...\n",
      "Document 58000 ... 41 journals... 101276 cited works... 15906 authors... 5000 terms used... 146309 skipped citations...\n",
      "Document 59000 ... 41 journals... 102072 cited works... 16132 authors... 5000 terms used... 148514 skipped citations...\n",
      "Document 60000 ... 41 journals... 102902 cited works... 16348 authors... 5000 terms used... 150958 skipped citations...\n",
      "Document 61000 ... 41 journals... 103719 cited works... 16584 authors... 5000 terms used... 153275 skipped citations...\n",
      "Document 62000 ... 41 journals... 104557 cited works... 16771 authors... 5000 terms used... 155894 skipped citations...\n",
      "Document 63000 ... 41 journals... 105309 cited works... 16983 authors... 5000 terms used... 158532 skipped citations...\n",
      "Document 64000 ... 41 journals... 106031 cited works... 17186 authors... 5000 terms used... 161205 skipped citations...\n",
      "Document 65000 ... 41 journals... 106714 cited works... 17393 authors... 5000 terms used... 163266 skipped citations...\n",
      "Document 66000 ... 41 journals... 107437 cited works... 17617 authors... 5000 terms used... 166218 skipped citations...\n",
      "Document 67000 ... 41 journals... 108166 cited works... 17806 authors... 5000 terms used... 168703 skipped citations...\n",
      "Document 68000 ... 41 journals... 108775 cited works... 17973 authors... 5000 terms used... 170995 skipped citations...\n",
      "Document 69000 ... 41 journals... 109531 cited works... 18173 authors... 5000 terms used... 173321 skipped citations...\n",
      "Document 70000 ... 41 journals... 110148 cited works... 18368 authors... 5000 terms used... 175411 skipped citations...\n",
      "parse error... ('No valid year found',) 10.2307/26650770\n",
      "Document 71000 ... 41 journals... 110787 cited works... 18568 authors... 5000 terms used... 177776 skipped citations...\n",
      "Document 72000 ... 41 journals... 111457 cited works... 18761 authors... 5000 terms used... 179801 skipped citations...\n",
      "Document 73000 ... 41 journals... 112161 cited works... 18950 authors... 5000 terms used... 182533 skipped citations...\n",
      "Document 74000 ... 41 journals... 112809 cited works... 19133 authors... 5000 terms used... 185080 skipped citations...\n",
      "Document 75000 ... 41 journals... 113486 cited works... 19323 authors... 5000 terms used... 187605 skipped citations...\n",
      "Document 76000 ... 41 journals... 114164 cited works... 19542 authors... 5000 terms used... 190423 skipped citations...\n",
      "Document 77000 ... 41 journals... 114868 cited works... 19754 authors... 5000 terms used... 193301 skipped citations...\n",
      "Document 78000 ... 41 journals... 115598 cited works... 19964 authors... 5000 terms used... 196309 skipped citations...\n",
      "Document 79000 ... 41 journals... 116150 cited works... 20119 authors... 5000 terms used... 198637 skipped citations...\n",
      "Document 80000 ... 41 journals... 116735 cited works... 20315 authors... 5000 terms used... 201062 skipped citations...\n",
      "Document 81000 ... 41 journals... 117264 cited works... 20513 authors... 5000 terms used... 203240 skipped citations...\n",
      "Document 82000 ... 41 journals... 117855 cited works... 20698 authors... 5000 terms used... 205745 skipped citations...\n",
      "Document 83000 ... 41 journals... 118493 cited works... 20879 authors... 5000 terms used... 208602 skipped citations...\n",
      "Document 84000 ... 41 journals... 119166 cited works... 21068 authors... 5000 terms used... 211585 skipped citations...\n",
      "Document 85000 ... 41 journals... 119693 cited works... 21270 authors... 5000 terms used... 214291 skipped citations...\n",
      "Document 86000 ... 41 journals... 120307 cited works... 21477 authors... 5000 terms used... 216951 skipped citations...\n",
      "Document 87000 ... 41 journals... 120839 cited works... 21643 authors... 5000 terms used... 219465 skipped citations...\n",
      "Document 88000 ... 41 journals... 121293 cited works... 21842 authors... 5000 terms used... 221596 skipped citations...\n",
      "Document 89000 ... 41 journals... 121774 cited works... 22009 authors... 5000 terms used... 223913 skipped citations...\n",
      "Document 90000 ... 41 journals... 122214 cited works... 22198 authors... 5000 terms used... 226400 skipped citations...\n",
      "Document 91000 ... 41 journals... 122597 cited works... 22377 authors... 5000 terms used... 228718 skipped citations...\n",
      "Document 92000 ... 41 journals... 123086 cited works... 22576 authors... 5000 terms used... 231504 skipped citations...\n",
      "Document 93000 ... 41 journals... 123565 cited works... 22743 authors... 5000 terms used... 234345 skipped citations...\n",
      "Document 94000 ... 41 journals... 123977 cited works... 22926 authors... 5000 terms used... 236583 skipped citations...\n",
      "Document 95000 ... 41 journals... 124469 cited works... 23121 authors... 5000 terms used... 238919 skipped citations...\n",
      "Document 96000 ... 41 journals... 124908 cited works... 23309 authors... 5000 terms used... 241344 skipped citations...\n",
      "Document 97000 ... 41 journals... 125308 cited works... 23472 authors... 5000 terms used... 243414 skipped citations...\n",
      "Document 98000 ... 41 journals... 125718 cited works... 23665 authors... 5000 terms used... 245746 skipped citations...\n",
      "Document 99000 ... 41 journals... 126113 cited works... 23820 authors... 5000 terms used... 248114 skipped citations...\n",
      "Document 100000 ... 41 journals... 126572 cited works... 24012 authors... 5000 terms used... 250894 skipped citations...\n",
      "Document 101000 ... 41 journals... 127034 cited works... 24224 authors... 5000 terms used... 253587 skipped citations...\n",
      "Document 102000 ... 41 journals... 127380 cited works... 24413 authors... 5000 terms used... 255910 skipped citations...\n",
      "Document 103000 ... 41 journals... 127796 cited works... 24572 authors... 5000 terms used... 258547 skipped citations...\n",
      "Document 104000 ... 41 journals... 128215 cited works... 24727 authors... 5000 terms used... 261493 skipped citations...\n",
      "Document 105000 ... 41 journals... 128585 cited works... 24880 authors... 5000 terms used... 264220 skipped citations...\n",
      "Document 106000 ... 41 journals... 128938 cited works... 25052 authors... 5000 terms used... 266602 skipped citations...\n",
      "Document 107000 ... 41 journals... 129251 cited works... 25204 authors... 5000 terms used... 268842 skipped citations...\n",
      "Document 108000 ... 41 journals... 129570 cited works... 25350 authors... 5000 terms used... 271031 skipped citations...\n",
      "Document 109000 ... 41 journals... 129915 cited works... 25529 authors... 5000 terms used... 273376 skipped citations...\n",
      "Document 110000 ... 41 journals... 130294 cited works... 25686 authors... 5000 terms used... 276117 skipped citations...\n",
      "Document 111000 ... 41 journals... 130713 cited works... 25875 authors... 5000 terms used... 279257 skipped citations...\n",
      "Document 112000 ... 41 journals... 131044 cited works... 26063 authors... 5000 terms used... 281668 skipped citations...\n",
      "Document 113000 ... 41 journals... 131360 cited works... 26228 authors... 5000 terms used... 284344 skipped citations...\n",
      "Document 114000 ... 41 journals... 131675 cited works... 26414 authors... 5000 terms used... 286840 skipped citations...\n",
      "Document 115000 ... 41 journals... 131929 cited works... 26564 authors... 5000 terms used... 288884 skipped citations...\n",
      "Document 116000 ... 41 journals... 132222 cited works... 26739 authors... 5000 terms used... 291412 skipped citations...\n",
      "Document 117000 ... 41 journals... 132535 cited works... 26917 authors... 5000 terms used... 294260 skipped citations...\n",
      "Document 118000 ... 41 journals... 132858 cited works... 27106 authors... 5000 terms used... 297170 skipped citations...\n",
      "Document 119000 ... 41 journals... 133146 cited works... 27277 authors... 5000 terms used... 299538 skipped citations...\n",
      "Document 120000 ... 41 journals... 133441 cited works... 27410 authors... 5000 terms used... 301953 skipped citations...\n",
      "Document 121000 ... 41 journals... 133714 cited works... 27581 authors... 5000 terms used... 304231 skipped citations...\n",
      "Document 122000 ... 41 journals... 133980 cited works... 27746 authors... 5000 terms used... 307236 skipped citations...\n",
      "Document 123000 ... 41 journals... 134259 cited works... 27914 authors... 5000 terms used... 309813 skipped citations...\n",
      "Document 124000 ... 41 journals... 134534 cited works... 28092 authors... 5000 terms used... 312436 skipped citations...\n",
      "Document 125000 ... 41 journals... 134778 cited works... 28270 authors... 5000 terms used... 314527 skipped citations...\n",
      "Document 126000 ... 41 journals... 135018 cited works... 28422 authors... 5000 terms used... 317288 skipped citations...\n",
      "Document 127000 ... 41 journals... 135279 cited works... 28582 authors... 5000 terms used... 319783 skipped citations...\n",
      "Document 128000 ... 41 journals... 135527 cited works... 28743 authors... 5000 terms used... 322288 skipped citations...\n",
      "Document 129000 ... 41 journals... 135787 cited works... 28927 authors... 5000 terms used... 324746 skipped citations...\n",
      "Document 130000 ... 41 journals... 136042 cited works... 29131 authors... 5000 terms used... 327564 skipped citations...\n",
      "Document 131000 ... 41 journals... 136292 cited works... 29274 authors... 5000 terms used... 330141 skipped citations...\n",
      "Document 132000 ... 41 journals... 136473 cited works... 29408 authors... 5000 terms used... 332211 skipped citations...\n",
      "Document 133000 ... 41 journals... 136679 cited works... 29611 authors... 5000 terms used... 335131 skipped citations...\n",
      "Document 134000 ... 41 journals... 136855 cited works... 29768 authors... 5000 terms used... 337725 skipped citations...\n",
      "Document 135000 ... 41 journals... 137033 cited works... 29918 authors... 5000 terms used... 340365 skipped citations...\n",
      "Document 136000 ... 41 journals... 137215 cited works... 30068 authors... 5000 terms used... 342621 skipped citations...\n",
      "Document 137000 ... 41 journals... 137432 cited works... 30236 authors... 5000 terms used... 345478 skipped citations...\n",
      "Document 138000 ... 41 journals... 137649 cited works... 30418 authors... 5000 terms used... 348388 skipped citations...\n",
      "Document 139000 ... 41 journals... 137839 cited works... 30576 authors... 5000 terms used... 350771 skipped citations...\n",
      "Document 140000 ... 41 journals... 138048 cited works... 30722 authors... 5000 terms used... 352909 skipped citations...\n",
      "Document 141000 ... 41 journals... 138248 cited works... 30859 authors... 5000 terms used... 355613 skipped citations...\n",
      "Document 142000 ... 41 journals... 138415 cited works... 31025 authors... 5000 terms used... 358375 skipped citations...\n",
      "Document 143000 ... 41 journals... 138578 cited works... 31185 authors... 5000 terms used... 361180 skipped citations...\n",
      "Document 144000 ... 41 journals... 138709 cited works... 31328 authors... 5000 terms used... 363344 skipped citations...\n",
      "Document 145000 ... 41 journals... 138847 cited works... 31483 authors... 5000 terms used... 365661 skipped citations...\n",
      "Document 146000 ... 41 journals... 139024 cited works... 31644 authors... 5000 terms used... 368445 skipped citations...\n",
      "Document 147000 ... 41 journals... 139146 cited works... 31769 authors... 5000 terms used... 370993 skipped citations...\n",
      "Document 148000 ... 41 journals... 139279 cited works... 31919 authors... 5000 terms used... 373686 skipped citations...\n",
      "Document 149000 ... 41 journals... 139429 cited works... 32094 authors... 5000 terms used... 376742 skipped citations...\n",
      "Document 150000 ... 41 journals... 139549 cited works... 32257 authors... 5000 terms used... 379191 skipped citations...\n",
      "Document 151000 ... 41 journals... 139694 cited works... 32414 authors... 5000 terms used... 381838 skipped citations...\n",
      "Document 152000 ... 41 journals... 139817 cited works... 32582 authors... 5000 terms used... 384377 skipped citations...\n",
      "Document 153000 ... 41 journals... 139922 cited works... 32713 authors... 5000 terms used... 386362 skipped citations...\n",
      "Document 154000 ... 41 journals... 140023 cited works... 32869 authors... 5000 terms used... 388951 skipped citations...\n",
      "Document 155000 ... 41 journals... 140135 cited works... 33030 authors... 5000 terms used... 391713 skipped citations...\n",
      "Document 156000 ... 41 journals... 140258 cited works... 33180 authors... 5000 terms used... 394594 skipped citations...\n",
      "Document 157000 ... 41 journals... 140336 cited works... 33311 authors... 5000 terms used... 396994 skipped citations...\n",
      "Document 158000 ... 41 journals... 140426 cited works... 33436 authors... 5000 terms used... 399465 skipped citations...\n",
      "Document 159000 ... 41 journals... 140507 cited works... 33605 authors... 5000 terms used... 401763 skipped citations...\n",
      "Document 160000 ... 41 journals... 140586 cited works... 33739 authors... 5000 terms used... 404166 skipped citations...\n",
      "Document 161000 ... 41 journals... 140682 cited works... 33860 authors... 5000 terms used... 406077 skipped citations...\n",
      "Document 162000 ... 41 journals... 140739 cited works... 33989 authors... 5000 terms used... 408415 skipped citations...\n",
      "Document 163000 ... 41 journals... 140809 cited works... 34171 authors... 5000 terms used... 412406 skipped citations...\n",
      "Document 164000 ... 41 journals... 140896 cited works... 34341 authors... 5000 terms used... 414383 skipped citations...\n",
      "Document 165000 ... 41 journals... 140948 cited works... 34470 authors... 5000 terms used... 416653 skipped citations...\n",
      "Document 166000 ... 41 journals... 141009 cited works... 34624 authors... 5000 terms used... 419013 skipped citations...\n",
      "Document 167000 ... 41 journals... 141079 cited works... 34764 authors... 5000 terms used... 422182 skipped citations...\n",
      "Document 168000 ... 41 journals... 141115 cited works... 34882 authors... 5000 terms used... 424153 skipped citations...\n",
      "Document 169000 ... 41 journals... 141161 cited works... 35013 authors... 5000 terms used... 426375 skipped citations...\n",
      "Document 170000 ... 41 journals... 141219 cited works... 35163 authors... 5000 terms used... 428739 skipped citations...\n",
      "Document 171000 ... 41 journals... 141283 cited works... 35294 authors... 5000 terms used... 431126 skipped citations...\n",
      "Document 172000 ... 41 journals... 141328 cited works... 35467 authors... 5000 terms used... 433852 skipped citations...\n",
      "Document 173000 ... 41 journals... 141371 cited works... 35595 authors... 5000 terms used... 436842 skipped citations...\n",
      "Document 174000 ... 41 journals... 141411 cited works... 35740 authors... 5000 terms used... 439170 skipped citations...\n",
      "Document 175000 ... 41 journals... 141447 cited works... 35891 authors... 5000 terms used... 441341 skipped citations...\n",
      "Document 176000 ... 41 journals... 141481 cited works... 36050 authors... 5000 terms used... 444104 skipped citations...\n",
      "Document 177000 ... 41 journals... 141517 cited works... 36212 authors... 5000 terms used... 446731 skipped citations...\n",
      "Document 178000 ... 41 journals... 141536 cited works... 36358 authors... 5000 terms used... 449314 skipped citations...\n",
      "Document 179000 ... 41 journals... 141558 cited works... 36489 authors... 5000 terms used... 451574 skipped citations...\n",
      "Document 180000 ... 41 journals... 141577 cited works... 36635 authors... 5000 terms used... 454248 skipped citations...\n",
      "Document 181000 ... 41 journals... 141588 cited works... 36774 authors... 5000 terms used... 456633 skipped citations...\n",
      "Document 182000 ... 41 journals... 141601 cited works... 36918 authors... 5000 terms used... 459043 skipped citations...\n",
      "Document 183000 ... 41 journals... 141605 cited works... 37063 authors... 5000 terms used... 461701 skipped citations...\n",
      "Document 184000 ... 41 journals... 141607 cited works... 37239 authors... 5000 terms used... 464242 skipped citations...\n"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "total_count = Counter()\n",
    "doc_count = Counter()\n",
    "pair_count = Counter()\n",
    "\n",
    "debug = False\n",
    "\n",
    "for i, (doi, metadata_str, ocr_str) in enumerate( file_iterator(zipfiles) ):\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Document\", i, \"...\", \n",
    "              len(cnt_doc['fj'].keys()), \"journals...\", \n",
    "              len(cnt_doc['c'].keys()), \"cited works...\", \n",
    "              len(cnt_doc['fa'].keys()), \"authors...\",\n",
    "              len(cnt_doc['t'].keys()), \"terms used...\",\n",
    "              citations_skipped, \"skipped citations...\"\n",
    "             )\n",
    "\n",
    "    try:\n",
    "        drep = clean_metadata( doi, metadata_str )\n",
    "        \n",
    "        # sometimes multiple journal names map onto the same journal, for all intents and purposes\n",
    "        if drep['journal'] in journal_map:\n",
    "            drep['journal'] = journal_map[drep['journal']]\n",
    "        \n",
    "        # only include journals in the list \"included_journals\"\n",
    "        if use_included_journals_filter and (drep['journal'] not in included_journals):\n",
    "            continue\n",
    "        \n",
    "        if debug: print(\"got meta\")\n",
    "\n",
    "        if drep['type'] != 'research-article':\n",
    "            continue\n",
    "            \n",
    "        # some types of titles should be immediately ignored\n",
    "        def title_looks_researchy(lt):\n",
    "            lt = lt.lower()\n",
    "            lt = lt.strip()\n",
    "\n",
    "            for x in [\"book review\", 'review essay', 'back matter', 'front matter', 'notes for contributors', 'publication received', 'errata:', 'erratum:']:\n",
    "                if x in lt:\n",
    "                    return False\n",
    "\n",
    "            for x in [\"commentary and debate\", 'erratum', '']:\n",
    "                if x == lt:\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        lt = drep['title'].lower()\n",
    "        if not title_looks_researchy(lt):\n",
    "            continue\n",
    "\n",
    "        # Don't process the document if there are no authors\n",
    "        if not len(drep['authors']):\n",
    "            continue\n",
    "\n",
    "        drep['content'] = get_content_string(ocr_str)\n",
    "        \n",
    "        drep['citations'] = []\n",
    "        \n",
    "        # loop through the matching parentheses in the document\n",
    "        for index, (parenStart, parenContents) in enumerate(getOuterParens(drep['content'])):\n",
    "            \n",
    "            citations = list(citation_iterator(parenContents))\n",
    "            if not len(citations):\n",
    "                continue\n",
    "\n",
    "                \n",
    "            citation = {\n",
    "                \"citations\": citations,\n",
    "                \"contextLeft\": drep['content'][parenStart-400+1:parenStart+1],\n",
    "                \"contextRight\": drep['content'][parenStart + len(parenContents) + 1:parenStart + len(parenContents) + 1 + 100],\n",
    "                \"where\": parenStart\n",
    "            }\n",
    "\n",
    "\n",
    "            # cut off any stuff before the first space\n",
    "            first_break_left = re.search(r\"[\\s\\.!\\?]+\", citation['contextLeft'])\n",
    "            if first_break_left is not None:\n",
    "                clean_start_left = citation['contextLeft'][first_break_left.end():]\n",
    "            else:\n",
    "                clean_start_left = citation['contextLeft']\n",
    "\n",
    "            # cut off any stuff after the last space\n",
    "            last_break_right = list(re.finditer(r\"[\\s\\.!\\?]+\", citation['contextRight']))\n",
    "            if len(last_break_right):\n",
    "                clean_end_right = citation['contextRight'][:last_break_right[-1].start()]\n",
    "            else:\n",
    "                clean_end_right = citation['contextRight']\n",
    "\n",
    "            # we don't want anything more than a sentence\n",
    "            \n",
    "            sentence_left = sent_tokenize(clean_start_left)\n",
    "            if len(sentence_left):\n",
    "                sentence_left = sentence_left[-1]\n",
    "            else:\n",
    "                sentence_left = \"\"\n",
    "\n",
    "            sentence_right = sent_tokenize(clean_end_right)[0]\n",
    "            if len(sentence_right):\n",
    "                sentence_right = sentence_right[0]\n",
    "            else:\n",
    "                sentence_right = \"\"\n",
    "\n",
    "            # finally, strip the parentheses from the string\n",
    "            sentence_left = sentence_left[:-1]\n",
    "            sentence_right = sentence_right[1:]\n",
    "\n",
    "            # add the thing in context\n",
    "            full = sentence_left + \"<CITATION>\" + sentence_right\n",
    "\n",
    "            citation['contextPure'] = sentence_left\n",
    "            #print(full)\n",
    "\n",
    "            drep['citations'].append(citation)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # now that we have all the information we need,\n",
    "        # we simply need to \"count\" this document in a few different ways\n",
    "        account_for(drep)\n",
    "\n",
    "\n",
    "    except ParseError as e:\n",
    "        print(\"parse error...\", e.args, doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('economic-outcomes',),\n",
       " ('max',),\n",
       " ('ethic-protestant',),\n",
       " ('relationship',),\n",
       " ('economic',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cnt_doc['t'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in cnt_doc['t'] if not '-' in x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(list(cnt_doc['t'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fj 41\n",
      "c 141608\n",
      "fa 37329\n",
      "t 5000\n",
      "fy 104\n",
      "fj.fy 1849\n",
      "c.fj 463963\n",
      "c.fy 588668\n",
      "fy.t 56127\n",
      "c.t 154241\n",
      "fj.t 40120\n",
      "c.fa 1328474\n",
      "fa.fj.fy 68269\n",
      "c.c 1019555\n",
      "c.c.fy 1122173\n"
     ]
    }
   ],
   "source": [
    "for k,v in cnt_doc.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Save the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sociology-jstor-basicall.doc ___ fj\n",
      "Saving sociology-jstor-basicall.doc ___ c\n",
      "Saving sociology-jstor-basicall.doc ___ fa\n",
      "Saving sociology-jstor-basicall.doc ___ t\n",
      "Saving sociology-jstor-basicall.doc ___ fy\n",
      "Saving sociology-jstor-basicall.doc ___ fj.fy\n",
      "Saving sociology-jstor-basicall.doc ___ c.fj\n",
      "Saving sociology-jstor-basicall.doc ___ c.fy\n",
      "Saving sociology-jstor-basicall.doc ___ fy.t\n",
      "Saving sociology-jstor-basicall.doc ___ c.t\n",
      "Saving sociology-jstor-basicall.doc ___ fj.t\n",
      "Saving sociology-jstor-basicall.doc ___ c.fa\n",
      "Saving sociology-jstor-basicall.doc ___ fa.fj.fy\n",
      "Saving sociology-jstor-basicall.doc ___ c.c\n",
      "Saving sociology-jstor-basicall.doc ___ c.c.fy\n"
     ]
    }
   ],
   "source": [
    "save_cnt(\"%s.doc\"%database_name, cnt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sociology-jstor-basicall.ind ___ fy\n",
      "Saving sociology-jstor-basicall.ind ___ c\n",
      "Saving sociology-jstor-basicall.ind ___ fj\n",
      "Saving sociology-jstor-basicall.ind ___ fj.fy\n",
      "Saving sociology-jstor-basicall.ind ___ c.fj\n",
      "Saving sociology-jstor-basicall.ind ___ c.fy\n",
      "Saving sociology-jstor-basicall.ind ___ t\n",
      "Saving sociology-jstor-basicall.ind ___ fy.t\n",
      "Saving sociology-jstor-basicall.ind ___ c.t\n",
      "Saving sociology-jstor-basicall.ind ___ fj.t\n",
      "Saving sociology-jstor-basicall.ind ___ c.fa\n",
      "Saving sociology-jstor-basicall.ind ___ fa.fj.fy\n",
      "Saving sociology-jstor-basicall.ind ___ fa\n",
      "Saving sociology-jstor-basicall.ind ___ c.c\n",
      "Saving sociology-jstor-basicall.ind ___ c.c.fy\n"
     ]
    }
   ],
   "source": [
    "save_cnt(\"%s.ind\"%database_name, cnt_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "G:\\My Drive\\projects\\qualitative analysis of literature\\post 5-12-2020\\git repository _ citation-deaths\\knowknow\\creating variables\\jstor counter (cnt).ipynb",
   "output_path": "G:\\My Drive\\projects\\qualitative analysis of literature\\post 5-12-2020\\git repository _ citation-deaths\\knowknow\\creating variables\\jstor counter (cnt).ipynb",
   "parameters": {},
   "start_time": "2020-05-23T00:16:31.253561",
   "version": "2.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
